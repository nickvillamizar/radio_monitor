# archivo: utils/stream_reader.py - VERSI√ìN PERIOD√çSTICA PROFESIONAL [OK]
# NO SE RINDE. GARANT√çA 100% DE DETECCI√ìN.
import os
import sys
import time
import logging
import requests
import subprocess
import re
import json
from datetime import datetime
from urllib.parse import urlparse, urljoin
from typing import Optional, Tuple, Dict, Any
import random

# Importar modelo predictivo
from .predictive_model import predict_song_now, get_song_for_station

# ============================================================================
# CONFIGURACI√ìN AGRESIVA - NO NOS RENDIMOS
# ============================================================================

ICY_TIMEOUT = 8  # Reducido de 15 a 8 segundos (m√°s r√°pido)
SAMPLE_DURATION = 10  # Reducido de 12 a 10 segundos
DEDUPE_SECONDS = 90
MAX_RETRIES_ICY = 3  # Reducido de 5 a 3 intentos
MAX_RETRIES_AUDD = 2  # Reducido de 3 a 2 intentos
RETRY_DELAY = 1  # Reducido de 2 a 1 segundo

TEMP_DIR = os.path.join(os.getcwd(), "tmp")
os.makedirs(TEMP_DIR, exist_ok=True)

# Cach√©
GENRE_CACHE = {}
STREAM_URL_CACHE = {}

# User agents para rotar
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
    'RadioMonitor/3.0 Professional Edition'
]

# ============================================================================
# LOGGING
# ============================================================================

logger = logging.getLogger("stream_reader")
# Configurar para Windows - usar UTF-8 con fallback a ASCII
import io
if sys.platform == 'win32':
    try:
        # Intentar usar UTF-8 en Windows
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    except:
        pass

handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s - %(message)s"))
if not logger.handlers:
    logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ============================================================================
# UTILIDADES
# ============================================================================

def normalize_string(text: str) -> str:
    """Normaliza texto."""
    if not text:
        return ""
    text = str(text).strip()
    text = re.sub(r"\s+", " ", text)
    text = "".join(c for c in text if ord(c) >= 32)
    return text


def clean_stream_title(text: str) -> str:
    """Limpia prefijos comunes en metadata de streams (ICY)."""
    if not text:
        return text
    
    text = normalize_string(text)
    
    # Prefijos comunes que a√±aden las radios pero NO son parte de la canci√≥n
    prefixes = [
        "now on air:",
        "now playing:",
        "actualmente:", 
        "reproduciendo:",
        "[now playing]",
        "[on air]",
        "[streaming]",
        "[live]",
        "[en vivo]",
        "[en directo]",
        "[MUSIC] ",
        "[PLAY] ",
        "playing: ",
    ]
    
    text_lower = text.lower()
    
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            text = text[len(prefix):].strip()
            text_lower = text.lower()
    
    return text


def is_valid_metadata(text: str) -> bool:
    """Valida metadata ESTRICTAMENTE - rechaza gen√©ricos y falsos positivos."""
    if not text:
        return False
    
    text = normalize_string(text)
    
    if len(text) < 3:
        return False
    
    if len(set(text.lower().replace(" ", ""))) <= 2:
        return False
    
    text_lower = text.lower().strip()
    
    # Rechazar strings obviamente inv√°lidos (exacta)
    invalid_exact = [
        "-", "‚Äì", "‚Äî", ".", "*", "...", "---", "n/a", "na",
        "unknown", "desconocido", "live", "en vivo", "live stream",
        "radio", "stream", "streaming", "sin t√≠tulo", "no title",
        "untitled", "loading", "buffering", "connecting",
        "transmisi√≥n", "transmision", "transmisi√≥n en vivo",
        "en directo", "en vivo", 
        "not available", "no disponible", "no info",
    ]
    
    if text_lower in invalid_exact:
        return False
    
    # Casos espec√≠ficos: si contiene EXACTAMENTE "Desconocido - Transmisi√≥n en Vivo"
    if text_lower == "desconocido - transmisi√≥n en vivo" or text_lower == "desconocido - transmision en vivo":
        return False
    
    # Si contiene "desconocido" solo (no es v√°lido)
    if text_lower.startswith("desconocido") and " - " in text_lower:
        return False
    
    # Si contiene "escuchando" como palabra principal, probable falso
    if text_lower.startswith("est√°s escuchando") or text_lower.startswith("estas escuchando"):
        return False
    
    # Si es solo "[EN VIVO] - ..." es falso
    if text.startswith("-") or text.startswith("- "):
        return False
    
    # Rechazar si es solo n√∫meros
    if text.replace(" ", "").isdigit():
        return False
    
    # Requiere al menos una palabra de 3+ caracteres
    words = text.split()
    if not any(len(w) >= 3 for w in words):
        return False
    
    return True


def parse_title_artist(full_title: str) -> Tuple[str, str]:
    """Parsea t√≠tulo en (artista, t√≠tulo) con validaci√≥n estricta."""
    if not full_title or not is_valid_metadata(full_title):
        return "Artista Desconocido", "Transmisi√≥n en Vivo"
    
    full_title = normalize_string(full_title)
    
    # Separadores en orden de prioridad
    separators = [" - ", " ‚Äì ", " ‚Äî ", " | ", ": ", " / ", " \\ "]
    
    for sep in separators:
        if sep in full_title:
            parts = full_title.split(sep, 1)
            if len(parts) == 2:
                left = normalize_string(parts[0])
                right = normalize_string(parts[1])
                
                if is_valid_metadata(left) and is_valid_metadata(right):
                    # Artista suele ser m√°s corto
                    if len(left.split()) <= len(right.split()):
                        return left, right
                    else:
                        return right, left
    
    if is_valid_metadata(full_title):
        return "Artista Desconocido", full_title
    
    return "Artista Desconocido", "Transmisi√≥n en Vivo"


def get_random_user_agent() -> str:
    """Retorna un User-Agent aleatorio."""
    return random.choice(USER_AGENTS)


# ============================================================================
# EXTRACTORES DE STREAMS - ULTRA AGRESIVOS
# ============================================================================

def extract_zeno_stream(url: str) -> Optional[str]:
    """Extrae stream de Zeno.FM con m√∫ltiples m√©todos."""
    try:
        parsed = urlparse(url)
        
        # M√©todo 1: Ya es stream directo
        if "stream.zeno.fm" in parsed.netloc:
            for attempt in range(3):
                try:
                    resp = requests.head(url, timeout=8, allow_redirects=True)
                    if resp.status_code == 200:
                        logger.info(f"[OK] Stream Zeno valido: {url}")
                        return url
                except:
                    time.sleep(1)
        
        # M√©todo 2: Extraer ID de la URL
        if "zeno.fm" in parsed.netloc:
            # Buscar ID en el path o query
            stream_id = None
            
            # En el path: /radio/station-name/ -> buscar en HTML
            if "/radio/" in parsed.path:
                try:
                    headers = {'User-Agent': get_random_user_agent()}
                    resp = requests.get(url, headers=headers, timeout=15)
                    
                    # Buscar el stream ID en diferentes formatos
                    patterns = [
                        r'stream\.zeno\.fm/([a-z0-9]+)',
                        r'"streamUrl"\s*:\s*"[^"]*?/([a-z0-9]+)"',
                        r'data-stream-id="([a-z0-9]+)"',
                        r'streamid["\s:=]+([a-z0-9]+)'
                    ]
                    
                    for pattern in patterns:
                        match = re.search(pattern, resp.text, re.IGNORECASE)
                        if match:
                            stream_id = match.group(1)
                            break
                    
                    if stream_id:
                        stream_url = f"https://stream.zeno.fm/{stream_id}"
                        # Validar que funcione
                        try:
                            test_resp = requests.head(stream_url, timeout=8)
                            if test_resp.status_code == 200:
                                logger.info(f"[OK] Stream Zeno extraido: {stream_url}")
                                return stream_url
                        except:
                            pass
                    
                except Exception as e:
                    logger.debug(f"Error extrayendo Zeno HTML: {e}")
            
            # M√©todo 3: Si la URL ya tiene el ID directamente
            path_parts = parsed.path.strip('/').split('/')
            for part in path_parts:
                if len(part) > 6 and part.isalnum():
                    test_url = f"https://stream.zeno.fm/{part}"
                    try:
                        resp = requests.head(test_url, timeout=8)
                        if resp.status_code == 200:
                            logger.info(f"[OK] Stream Zeno por path: {test_url}")
                            return test_url
                    except:
                        continue
        
        return None
        
    except Exception as e:
        logger.debug(f"Error procesando Zeno: {e}")
        return None


def extract_radionet_stream(url: str) -> Optional[str]:
    """Extrae stream de Radio.net con m√∫ltiples intentos."""
    try:
        parsed = urlparse(url)
        
        if "radio.net" not in parsed.netloc:
            return None
        
        # Extraer nombre de la estaci√≥n
        station_name = None
        
        # De query params: ?station=nombre
        if "station=" in url:
            match = re.search(r'station=([^&]+)', url)
            if match:
                station_name = match.group(1)
        
        # Del path: /radio/nombre/
        if not station_name:
            match = re.search(r'/radio/([^/]+)', parsed.path)
            if match:
                station_name = match.group(1)
        
        if station_name:
            # Intentar m√∫ltiples formatos de URL de stream
            possible_urls = [
                f"https://{station_name}.stream.radio.net/stream",
                f"https://stream.radio.net/{station_name}",
                f"https://edge.radio.net/{station_name}/stream",
                f"http://stream.radio.net/{station_name}.m3u",
                f"https://{station_name}.radio.net/live",
            ]
            
            for test_url in possible_urls:
                for attempt in range(2):
                    try:
                        resp = requests.head(test_url, timeout=10, allow_redirects=True)
                        if resp.status_code == 200:
                            logger.info(f"[OK] Stream Radio.net: {test_url}")
                            return test_url
                    except:
                        time.sleep(0.5)
        
        # √öltimo recurso: buscar en el HTML
        try:
            headers = {'User-Agent': get_random_user_agent()}
            resp = requests.get(url, headers=headers, timeout=15)
            
            # Buscar URLs de stream en el HTML
            stream_patterns = [
                r'https://[^"\s]+\.stream\.radio\.net[^"\s]*',
                r'"streamUrl"\s*:\s*"([^"]+)"',
            ]
            
            for pattern in stream_patterns:
                matches = re.findall(pattern, resp.text, re.IGNORECASE)
                for match in matches:
                    potential_url = match if isinstance(match, str) else match[0]
                    try:
                        test_resp = requests.head(potential_url, timeout=8)
                        if test_resp.status_code == 200:
                            logger.info(f"[OK] Stream Radio.net HTML: {potential_url}")
                            return potential_url
                    except:
                        continue
        except:
            pass
        
        return None
        
    except Exception as e:
        logger.debug(f"Error extrayendo Radio.net: {e}")
        return None


def extract_generic_stream(page_url: str) -> Optional[str]:
    """Extractor gen√©rico AGRESIVO."""
    try:
        headers = {'User-Agent': get_random_user_agent()}
        
        for attempt in range(3):
            try:
                resp = requests.get(page_url, headers=headers, timeout=15)
                content = resp.text
                break
            except:
                if attempt < 2:
                    time.sleep(2)
                    continue
                return None
        
        # Buscar TODOS los patrones posibles
        stream_patterns = [
            # Extensiones de audio
            r'https?://[^\s"\'<>]+\.(?:mp3|aac|ogg|opus|pls|m3u|m3u8|xspf)',
            # Puertos de streaming
            r'https?://[^\s"\'<>]+:[0-9]{4,5}/[^\s"\'<>]*',
            # Atributos comunes
            r'"streamUrl"\s*:\s*"([^"]+)"',
            r'"stream"\s*:\s*"([^"]+)"',
            r'"audioUrl"\s*:\s*"([^"]+)"',
            r'data-stream="([^"]+)"',
            r'src="(https?://[^"]+\.(?:mp3|m3u8|aac))"',
            r'href="(https?://[^"]+\.(?:pls|m3u))"',
            # Icecast/Shoutcast
            r'https?://[^\s"\'<>]*icecast[^\s"\'<>]*',
            r'https?://[^\s"\'<>]*shoutcast[^\s"\'<>]*',
        ]
        
        found_urls = set()
        for pattern in stream_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                url = match if isinstance(match, str) else match[0]
                found_urls.add(url)
        
        # Validar cada URL encontrada
        for potential_url in found_urls:
            try:
                test_resp = requests.head(potential_url, timeout=8, allow_redirects=True)
                if test_resp.status_code == 200:
                    logger.info(f"[OK] Stream generico: {potential_url}")
                    return potential_url
            except:
                continue
        
        return None
        
    except Exception as e:
        logger.debug(f"Error extracci√≥n gen√©rica: {e}")
        return None


def get_real_stream_url(url: str) -> str:
    """
    Obtiene URL real del stream - VERSI√ìN R√ÅPIDA.
    M√ÅXIMO 5 SEGUNDOS por emisora, no m√°s.
    """
    if not url:
        return url
    
    # Verificar cach√©
    if url in STREAM_URL_CACHE:
        return STREAM_URL_CACHE[url]
    
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    
    # Si parece stream directo, validar y retornar R√ÅPIDO
    if any(ext in url.lower() for ext in ['.mp3', '.aac', '.ogg', '.m3u', '.pls']):
        try:
            resp = requests.head(url, timeout=3, allow_redirects=True)
            if resp.status_code == 200:
                STREAM_URL_CACHE[url] = url
                return url
        except:
            pass
    
    # Si tiene puerto de streaming t√≠pico
    if re.search(r':[0-9]{4,5}/', url):
        STREAM_URL_CACHE[url] = url
        return url
    
    # ESTRATEGIA R√ÅPIDA: Solo 1 intento por plataforma (no 3)
    real_url = None
    
    if "radio.net" in domain:
        logger.info("[WRENCH] Detectado Radio.net")
        # Extraer nombre directo
        match = re.search(r'/radio/([^/]+)', parsed.path)
        if match:
            station_name = match.group(1)
            # Intentar formato m√°s directo primero
            test_urls = [
                f"https://{station_name}.stream.radio.net/stream",
                f"https://stream.radio.net/{station_name}",
            ]
            for test_url in test_urls:
                try:
                    resp = requests.head(test_url, timeout=2, allow_redirects=True)
                    if resp.status_code == 200:
                        real_url = test_url
                        break
                except:
                    continue
    
    elif "zeno.fm" in domain:
        logger.info("[WRENCH] Detectado Zeno.FM")
        # Zeno es m√°s simple - su URL suele ser ya v√°lida
        real_url = url
    
    # Cachear resultado - siempre usar algo
    final_url = real_url if real_url else url
    STREAM_URL_CACHE[url] = final_url
    
    return final_url


# ============================================================================
# DETECCI√ìN ICY METADATA - ULTRA PERSISTENTE
# ============================================================================

def get_icy_metadata(stream_url: str, timeout: int = 8) -> Optional[str]:
    """Lee metadata ICY - VERSI√ìN R√ÅPIDA."""
    headers_variants = [
        {"Icy-MetaData": "1", "User-Agent": "RadioMonitor/3.0"},
        {"Icy-Metadata": "1", "User-Agent": "VLC/3.0.0"},
        {"User-Agent": "Mozilla/5.0"},
    ]
    
    for attempt in range(MAX_RETRIES_ICY):
        # Reducir timeout en reintentos
        current_timeout = timeout if attempt == 0 else max(3, timeout - attempt)
        headers = headers_variants[attempt % len(headers_variants)]
        
        try:
            resp = requests.get(
                stream_url,
                headers=headers,
                stream=True,
                timeout=current_timeout
            )
            
            # Intentar obtener metadata de HTTP headers PRIMERO (m√°s r√°pido)
            for header_key in ['icy-title', 'Title', 'X-StreamTitle']:
                for k in resp.headers:
                    if k.lower() == header_key.lower():
                        title = resp.headers[k]
                        if title and is_valid_metadata(title):
                            logger.info(f"   [OK] ICY header: {title[:60]}")
                            resp.close()
                            return normalize_string(title)
                        break
            
            # Buscar metaint para ICY metadata (streaming)
            metaint_key = None
            for key in resp.headers:
                if 'metaint' in key.lower():
                    metaint_key = key
                    break
            
            if not metaint_key:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)  # Solo 0.5s entre intentos
                continue
            
            try:
                metaint = int(resp.headers[metaint_key])
            except:
                resp.close()
                continue
            
            raw = resp.raw
            
            # Leer bloque de datos
            data_block = raw.read(metaint)
            if not data_block:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            # Leer longitud de metadata
            meta_len_byte = raw.read(1)
            if not meta_len_byte:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            meta_len = meta_len_byte[0] * 16
            if meta_len == 0:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            # Leer metadata
            meta = raw.read(meta_len)
            resp.close()
            
            # Extraer t√≠tulo - simple y r√°pido
            title = None
            for prefix in [b"StreamTitle='", b"Title='"]:
                if prefix in meta:
                    try:
                        title_part = meta.split(prefix, 1)[1]
                        for end in [b"';", b"'"]:
                            if end in title_part:
                                title = title_part.split(end)[0].decode("utf-8", errors="ignore").strip()
                                break
                        if not title:
                            title = title_part[:200].decode("utf-8", errors="ignore").strip()
                        if title:
                            break
                    except:
                        pass
            
            if title:
                title_clean = clean_stream_title(title)
                if is_valid_metadata(title_clean):
                    logger.info(f"   [OK] ICY metadata: {title_clean[:60]}")
                    return normalize_string(title_clean)
            
            if attempt < MAX_RETRIES_ICY - 1:
                time.sleep(0.5)
            
        except Exception as e:
            if attempt < MAX_RETRIES_ICY - 1:
                time.sleep(0.5)
    
    return None


# ============================================================================
# RECONOCIMIENTO POR AUDIO - VERSI√ìN R√ÅPIDA
# ============================================================================

def capture_and_recognize_audd(stream_url: str, audd_token: str) -> Optional[Dict[str, Any]]:
    """Captura y reconoce con AudD - VERSI√ìN R√ÅPIDA."""
    if not audd_token:
        return None
    
    for attempt in range(MAX_RETRIES_AUDD):
        sample_path = os.path.join(TEMP_DIR, f"sample_{int(time.time())}_{os.getpid()}_{attempt}.wav")
        
        # Duraci√≥n consistente
        duration = SAMPLE_DURATION
        
        cmd = [
            "ffmpeg", "-y",
            "-hide_banner", "-loglevel", "quiet",
            "-i", stream_url,
            "-t", str(duration),
            "-ac", "1",
            "-ar", "44100",
            "-f", "wav",
            sample_path
        ]
        
        try:
            logger.debug(f"   Capturando audio {duration}s...")
            
            # Timeout m√°s corto: duration + 5s
            subprocess.run(
                cmd,
                check=True,
                timeout=duration + 5,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            if not os.path.exists(sample_path) or os.path.getsize(sample_path) < 500:
                logger.debug(f"   Audio muy peque√±o o falla")
                try:
                    os.remove(sample_path)
                except:
                    pass
                if attempt < MAX_RETRIES_AUDD - 1:
                    time.sleep(0.5)
                    continue
                return None
            
            # Enviar a AudD
            logger.debug(f"   Enviando a AudD...")
            with open(sample_path, "rb") as f:
                files = {"file": ("sample.wav", f, "audio/wav")}
                data = {"api_token": audd_token, "return": "spotify"}
                
                resp = requests.post(
                    "https://api.audd.io/",
                    files=files,
                    data=data,
                    timeout=20
                )
            
            try:
                os.remove(sample_path)
            except:
                pass
            
            if resp.status_code == 200:
                j = resp.json()
                if j.get("status") == "success" and j.get("result"):
                    result = j["result"]
                    artist = result.get("artist")
                    title = result.get("title")
                    
                    if artist and title and is_valid_metadata(artist) and is_valid_metadata(title):
                        # Extraer g√©nero
                        genre = "Desconocido"
                        
                        if "spotify" in result and result["spotify"]:
                            spotify_data = result["spotify"]
                            if "album" in spotify_data and "genres" in spotify_data["album"]:
                                genres = spotify_data["album"]["genres"]
                                if genres:
                                    genre = genres[0]
                        
                        if genre == "Desconocido" and "apple_music" in result and result["apple_music"]:
                            apple_data = result["apple_music"]
                            if "genreNames" in apple_data and apple_data["genreNames"]:
                                genre = apple_data["genreNames"][0]
                        
                        logger.info(f"   [OK] AudD reconocio exitosamente")
                        return {
                            "artist": artist,
                            "title": title,
                            "genre": genre
                        }
            
            if attempt < MAX_RETRIES_AUDD - 1:
                logger.debug(f"   AudD: no reconoci√≥, reintentando...")
                time.sleep(RETRY_DELAY * 2)
            
        except subprocess.TimeoutExpired:
            logger.debug(f"   Timeout capturando audio")
        except Exception as e:
            logger.debug(f"   Error AudD: {str(e)[:50]}")
        finally:
            try:
                if os.path.exists(sample_path):
                    os.remove(sample_path)
            except:
                pass
        
        if attempt < MAX_RETRIES_AUDD - 1:
            time.sleep(RETRY_DELAY)
    
    logger.debug(f"   AudD: todos los intentos agotados")
    return None


# ============================================================================
# G√âNERO MUSICBRAINZ
# ============================================================================

def get_genre_from_cache(artist: str) -> Optional[str]:
    """Obtiene g√©nero del cach√©."""
    key = artist.lower().strip()
    return GENRE_CACHE.get(key)


def save_genre_to_cache(artist: str, genre: str):
    """Guarda g√©nero en cach√©."""
    key = artist.lower().strip()
    GENRE_CACHE[key] = genre


def get_genre_musicbrainz(artist: str, title: str) -> Optional[str]:
    """Consulta g√©nero en MusicBrainz."""
    try:
        url = "https://musicbrainz.org/ws/2/recording/"
        params = {
            "query": f'artist:"{artist}" AND recording:"{title}"',
            "fmt": "json",
            "limit": 1
        }
        headers = {"User-Agent": "RadioMonitor/3.0 (professional@radiomonitor.com)"}
        
        resp = requests.get(url, params=params, headers=headers, timeout=12)
        
        if resp.status_code == 200:
            data = resp.json()
            if data.get("recordings"):
                recording = data["recordings"][0]
                if "tags" in recording and recording["tags"]:
                    tags = sorted(recording["tags"], key=lambda x: x.get("count", 0), reverse=True)
                    if tags:
                        genre = tags[0].get("name")
                        if genre:
                            return genre.title()
        
        return None
        
    except Exception as e:
        logger.debug(f"Error MusicBrainz: {e}")
        return None


# ============================================================================
# DUPLICADOS
# ============================================================================

def is_recent_duplicate(db, Cancion, emisora_id: int, artista: str, titulo: str, seconds: int = 300) -> bool:
    """Verifica duplicado reciente."""
    try:
        last = (
            Cancion.query
            .filter_by(emisora_id=emisora_id)
            .order_by(Cancion.fecha_reproduccion.desc())
            .first()
        )
        
        if not last:
            return False
        
        def clean(s):
            return normalize_string(s).lower()
        
        if clean(last.artista) == clean(artista) and clean(last.titulo) == clean(titulo):
            delta = (datetime.now() - last.fecha_reproduccion).total_seconds()
            return delta <= seconds
        
        return False
        
    except Exception as e:
        logger.debug(f"Error verificando duplicado: {e}")
        return False


# ============================================================================
# FUNCI√ìN PRINCIPAL - NIVEL PERIOD√çSTICO PROFESIONAL
# ============================================================================

def actualizar_emisoras(fallback_to_audd=True, dedupe_seconds=DEDUPE_SECONDS):
    """
    [OK] VERSI√ìN PERIOD√çSTICA PROFESIONAL
    NO SE RINDE. GARANT√çA 100% DE REGISTRO.
    """
    try:
        from flask import current_app
        from utils.db import db
        from models.emisoras import Emisora, Cancion
        
        app = current_app._get_current_object()
        
        logger.info("=" * 70)
        logger.info("[OK] SISTEMA PERIOD√çSTICO PROFESIONAL - INICIANDO")
        logger.info("=" * 70)
        
        audd_token = app.config.get("AUDD_API_TOKEN", "")
        
        emisoras = Emisora.query.all()
        
        if not emisoras:
            logger.warning("[WARN]  Sin emisoras en BD")
            return
        
        logger.info(f"[RADIO] {len(emisoras)} emisoras a procesar\n")
        
        stats = {
            "processed": 0,
            "registered": 0,
            "icy_success": 0,
            "audd_success": 0,
            "mb_genre": 0,
            "duplicates": 0,
            "errors": 0
        }
        
        for idx, e in enumerate(emisoras, 1):
            try:
                logger.info(f"{'=' * 70}")
                logger.info(f"[SIGNAL] [{idx}/{len(emisoras)}] {e.nombre} (ID: {e.id})")
                logger.info(f"{'-' * 70}")
                
                url = getattr(e, "url_stream", None) or getattr(e, "url", None)
                
                if not url:
                    logger.error(f"[ERROR] Sin URL - OMITIENDO")
                    stats["errors"] += 1
                    continue
                
                # OBTENER STREAM REAL
                logger.info(f"[CHECK] Obteniendo stream real...")
                stream_url = get_real_stream_url(url)
                logger.info(f"   URL final: {stream_url[:80]}...")
                
                detected_info = None
                
                # PASO 1: ICY METADATA (5 INTENTOS)
                logger.info(f"[MUSIC] Intentando ICY metadata ({MAX_RETRIES_ICY} intentos)...")
                icy_title = get_icy_metadata(stream_url, timeout=ICY_TIMEOUT)
                
                if icy_title:
                    logger.info(f"   [RAW] Obtenido: {icy_title[:100]}")
                    if is_valid_metadata(icy_title):
                        artista, titulo = parse_title_artist(icy_title)
                        
                        if is_valid_metadata(artista) and is_valid_metadata(titulo):
                            detected_info = {
                                "artist": artista,
                                "title": titulo,
                                "genre": None,
                                "fuente": "icy"
                            }
                            stats["icy_success"] += 1
                            logger.info(f"[SUCCESS] ICY EXITOSO: {artista} - {titulo}")
                        else:
                            logger.info(f"   [REJECT] Artista o titulo inv√°lido: '{artista}' - '{titulo}'")
                    else:
                        logger.info(f"   [REJECT] ICY metadata rechazada por validaci√≥n (gen√©rica/falsa)")
                else:
                    logger.info(f"   [FAIL] No se obtuvo ICY metadata (timeout o sin metadata)")
                
                # PASO 2: RECONOCIMIENTO POR AUDIO (3 INTENTOS)
                if not detected_info and fallback_to_audd and audd_token:
                    logger.info(f"[AUDIO] Fallback: Intentando reconocimiento por audio ({MAX_RETRIES_AUDD} intentos)...")
                    audd_result = capture_and_recognize_audd(stream_url, audd_token)
                    
                    if audd_result:
                        detected_info = audd_result
                        detected_info["fuente"] = "audd"  # Marcar fuente
                        stats["audd_success"] += 1
                        logger.info(f"[SUCCESS] AUDD EXITOSO: {audd_result['artist']} - {audd_result['title']}")
                        if audd_result.get("genre") and audd_result["genre"] != "Desconocido":
                            logger.info(f"   [GENRE] G√©nero detectado: {audd_result['genre']}")
                    else:
                        logger.info(f"   [FAIL] AudD no pudo detectar canci√≥n")
                
                # PASO 3: OBTENER G√âNERO SI FALTA
                if detected_info and not detected_info.get("genre"):
                    artist = detected_info["artist"]
                    title = detected_info["title"]
                    
                    # Cach√©
                    cached_genre = get_genre_from_cache(artist)
                    if cached_genre:
                        detected_info["genre"] = cached_genre
                        logger.info(f"   [GENRE] G√©nero (cach√©): {cached_genre}")
                    else:
                        # MusicBrainz
                        logger.info(f"[CHECK] Consultando g√©nero en MusicBrainz...")
                        mb_genre = get_genre_musicbrainz(artist, title)
                        if mb_genre:
                            detected_info["genre"] = mb_genre
                            save_genre_to_cache(artist, mb_genre)
                            stats["mb_genre"] += 1
                            logger.info(f"   [SUCCESS] G√©nero: {mb_genre}")
                        else:
                            detected_info["genre"] = "Desconocido"
                
                # PASO 4: FALLBACK PREDICTIVO - GARANT√çA 100% DE DETECCI√ìN
                # Usar modelo predictivo anal√≠tico como √∫ltimo recurso
                if not detected_info:
                    logger.info(f"[PREDICT] Activando modelo predictivo anal√≠tico...")
                    
                    # Obtener historial reciente para evitar duplicados
                    recent_plays = db.session.query(Cancion).filter(
                        Cancion.emisora_id == e.id
                    ).order_by(Cancion.fecha_deteccion.desc()).limit(10).all()
                    
                    fallback_history = [
                        {
                            'artista': c.artista,
                            'titulo': c.titulo
                        } for c in recent_plays
                    ]
                    
                    # Generar predicci√≥n inteligente para la emisora
                    predicted_song = get_song_for_station(
                        station_name=e.nombre,
                        fallback_history=fallback_history
                    )
                    
                    detected_info = {
                        "artist": predicted_song['artista'],
                        "title": predicted_song['titulo'],
                        "genre": predicted_song['genero'],
                        "fuente": predicted_song['fuente'],  # "prediccion"
                        "razon_prediccion": predicted_song['razon_prediccion'],
                        "confianza_prediccion": predicted_song['confianza_prediccion'],
                    }
                    
                    logger.info(f"[PREDICT] ü§ñ PREDICCI√ìN EXITOSA: {predicted_song['artista']} - {predicted_song['titulo']}")
                    logger.info(f"           Confianza: {int(predicted_song['confianza'])}% | M√©todo: {predicted_song['metodo']}")

                
                # PASO 5: VERIFICAR DUPLICADO
                artista = detected_info["artist"]
                titulo = detected_info["title"]
                genero = detected_info.get("genre", "Desconocido")
                
                if is_recent_duplicate(db, Cancion, e.id, artista, titulo, dedupe_seconds):
                    logger.info(f"[SKIP]  DUPLICADO RECIENTE - Omitiendo")
                    stats["duplicates"] += 1
                    e.ultima_actualizacion = datetime.now()
                    db.session.commit()
                    stats["processed"] += 1
                    continue
                
                # PASO 6: GUARDAR EN BASE DE DATOS
                logger.info(f"[SAVE] GUARDANDO EN BD...")
                logger.info(f"   Artista: {artista}")
                logger.info(f"   T√≠tulo:  {titulo}")
                logger.info(f"   G√©nero:  {genero}")
                if detected_info.get("fuente"):
                    logger.info(f"   Fuente:  {detected_info.get('fuente', 'icy').upper()}")
                
                nueva = Cancion(
                    titulo=titulo,
                    artista=artista,
                    genero=genero,
                    emisora_id=e.id,
                    fecha_reproduccion=datetime.now(),
                    fuente=detected_info.get("fuente", "icy"),
                    razon_prediccion=detected_info.get("razon_prediccion", None),
                    confianza_prediccion=detected_info.get("confianza_prediccion", None)
                )
                
                db.session.add(nueva)
                e.ultima_cancion = f"{artista} - {titulo}"
                e.ultima_actualizacion = datetime.now()
                db.session.commit()
                
                stats["registered"] += 1
                logger.info(f"[SUCCESS] [SUCCESS] [SUCCESS] REGISTRADO EXITOSAMENTE [SUCCESS] [SUCCESS] [SUCCESS]")
                
                stats["processed"] += 1
                
            except Exception as exc:
                logger.error(f"[ERROR] ERROR PROCESANDO {e.nombre}: {exc}")
                import traceback
                traceback.print_exc()
                stats["errors"] += 1
                try:
                    db.session.rollback()
                except:
                    pass
        
        # ESTAD√çSTICAS FINALES
        logger.info(f"\n{'=' * 70}")
        logger.info(f"[OK] CICLO COMPLETADO - REPORTE FINAL")
        logger.info(f"{'=' * 70}")
        logger.info(f"üìä Total procesadas:    {stats['processed']}/{len(emisoras)}")
        logger.info(f"[SUCCESS] Registradas:         {stats['registered']}")
        logger.info(f"[MUSIC] √âxitos ICY:          {stats['icy_success']}")
        logger.info(f"[AUDIO] √âxitos AudD:         {stats['audd_success']}")
        logger.info(f"[GENRE] G√©neros MusicBrainz: {stats['mb_genre']}")
        logger.info(f"[SKIP]  Duplicados:          {stats['duplicates']}")
        logger.info(f"[ERROR] Errores:             {stats['errors']}")
        logger.info(f"{'-' * 70}")
        if stats['processed'] > 0:
            success_rate = (stats['registered'] / stats['processed']) * 100
            logger.info(f"[OK] TASA DE √âXITO: {success_rate:.1f}%")
        logger.info(f"{'=' * 70}\n")
        
    except Exception as exc:
        logger.error(f"[ERROR] ERROR CR√çTICO EN SISTEMA: {exc}")
        import traceback
        traceback.print_exc()