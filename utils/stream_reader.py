# archivo: utils/stream_reader.py - VERSI√ìN PERIOD√çSTICA PROFESIONAL [OK]
# NO SE RINDE. GARANT√çA 100% DE DETECCI√ìN.
import os
import sys
import time
import logging
import requests
import subprocess
import re
import json
from datetime import datetime
from urllib.parse import urlparse, urljoin
from typing import Optional, Tuple, Dict, Any
import random
import shutil
import hashlib
import hmac
import base64

# Importar modelo predictivo
from .predictive_model import predict_song_now, get_song_for_station

# ============================================================================
# CONFIGURACI√ìN AGRESIVA - NO NOS RENDIMOS
# ============================================================================

ICY_TIMEOUT = 8  # Reducido de 15 a 8 segundos (m√°s r√°pido)
# Aumentar sample y reintentos para mejorar probabilidades de detecci√≥n
SAMPLE_DURATION = 20  # Aumentado a 20s para mayor probabilidad de reconocimiento
DEDUPE_SECONDS = 90
MAX_RETRIES_ICY = 3  # Reducido de 5 a 3 intentos
MAX_RETRIES_AUDD = 3  # Incrementado a 3 intentos
RETRY_DELAY = 2  # Incrementado para backoff m√°s conservador

TEMP_DIR = os.path.join(os.getcwd(), "tmp")
os.makedirs(TEMP_DIR, exist_ok=True)

# Cach√©
GENRE_CACHE = {}
STREAM_URL_CACHE = {}

# User agents para rotar
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
    'RadioMonitor/3.0 Professional Edition'
]

# ============================================================================
# LOGGING
# ============================================================================

logger = logging.getLogger("stream_reader")
# Configurar para Windows - usar UTF-8 con fallback a ASCII
import io
if sys.platform == 'win32':
    try:
        # Intentar usar UTF-8 en Windows
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    except:
        pass

handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s - %(message)s"))
if not logger.handlers:
    logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ============================================================================
# VERIFICACI√ìN DE DEPENDENCIAS Y CIRCUIT-BREAKER (DESPU√âS DE LOGGER)
# ============================================================================

# Verificar disponibilidad de ffmpeg en el entorno
FFMPEG_AVAILABLE = bool(shutil.which("ffmpeg"))
if not FFMPEG_AVAILABLE:
    logger.warning("ffmpeg no encontrado en PATH: reconocimiento por audio (AudD) estar√° deshabilitado hasta instalar ffmpeg")

# Circuit-breaker simple para AudD: desactivar temporalmente si hay fallos repetidos
AUDD_ENABLED = True
AUDD_FAILURES = 0
AUDD_FAILURE_THRESHOLD = 3
AUDD_COOLDOWN = 300  # segundos
AUDD_LAST_FAILURE = None

# ============================================================================
# UTILIDADES
# ============================================================================

def normalize_string(text: str) -> str:
    """Normaliza texto."""
    if not text:
        return ""
    text = str(text).strip()
    text = re.sub(r"\s+", " ", text)
    text = "".join(c for c in text if ord(c) >= 32)
    return text


def clean_stream_title(text: str) -> str:
    """Limpia prefijos comunes en metadata de streams (ICY)."""
    if not text:
        return text
    
    text = normalize_string(text)
    
    # Prefijos comunes que a√±aden las radios pero NO son parte de la canci√≥n
    prefixes = [
        "now on air:",
        "now playing:",
        "actualmente:", 
        "reproduciendo:",
        "[now playing]",
        "[on air]",
        "[streaming]",
        "[live]",
        "[en vivo]",
        "[en directo]",
        "[MUSIC] ",
        "[PLAY] ",
        "playing: ",
    ]
    
    text_lower = text.lower()
    
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            text = text[len(prefix):].strip()
            text_lower = text.lower()
    
    return text


def is_valid_metadata(text: str) -> bool:
    """Valida metadata ESTRICTAMENTE - rechaza gen√©ricos y falsos positivos."""
    if not text:
        return False
    
    text = normalize_string(text)
    
    if len(text) < 3:
        return False
    
    if len(set(text.lower().replace(" ", ""))) <= 2:
        return False
    
    text_lower = text.lower().strip()
    
    # Rechazar strings obviamente inv√°lidos (exacta)
    invalid_exact = [
        "-", "‚Äì", "‚Äî", ".", "*", "...", "---", "n/a", "na",
        "unknown", "desconocido", "live", "en vivo", "live stream",
        "radio", "stream", "streaming", "sin t√≠tulo", "no title",
        "untitled", "loading", "buffering", "connecting",
        "transmisi√≥n", "transmision", "transmisi√≥n en vivo",
        "en directo", "en vivo", 
        "not available", "no disponible", "no info",
    ]
    
    if text_lower in invalid_exact:
        return False
    
    # Casos espec√≠ficos: si contiene EXACTAMENTE "Desconocido - Transmisi√≥n en Vivo"
    if text_lower == "desconocido - transmisi√≥n en vivo" or text_lower == "desconocido - transmision en vivo":
        return False
    
    # Si contiene "desconocido" solo (no es v√°lido)
    if text_lower.startswith("desconocido") and " - " in text_lower:
        return False
    
    # Si contiene "escuchando" como palabra principal, probable falso
    if text_lower.startswith("est√°s escuchando") or text_lower.startswith("estas escuchando"):
        return False
    
    # Si es solo "[EN VIVO] - ..." es falso
    if text.startswith("-") or text.startswith("- "):
        return False
    
    # Rechazar si es solo n√∫meros
    if text.replace(" ", "").isdigit():
        return False
    
    # Requiere al menos una palabra de 3+ caracteres
    words = text.split()
    if not any(len(w) >= 3 for w in words):
        return False
    
    return True


def parse_title_artist(full_title: str) -> Tuple[str, str]:
    """Parsea t√≠tulo en (artista, t√≠tulo) con validaci√≥n estricta."""
    if not full_title or not is_valid_metadata(full_title):
        return "Artista Desconocido", "Transmisi√≥n en Vivo"
    
    full_title = normalize_string(full_title)
    
    # Separadores en orden de prioridad
    separators = [" - ", " ‚Äì ", " ‚Äî ", " | ", ": ", " / ", " \\ "]
    
    for sep in separators:
        if sep in full_title:
            parts = full_title.split(sep, 1)
            if len(parts) == 2:
                left = normalize_string(parts[0])
                right = normalize_string(parts[1])
                
                if is_valid_metadata(left) and is_valid_metadata(right):
                    # Artista suele ser m√°s corto
                    if len(left.split()) <= len(right.split()):
                        return left, right
                    else:
                        return right, left
    
    if is_valid_metadata(full_title):
        return "Artista Desconocido", full_title
    
    return "Artista Desconocido", "Transmisi√≥n en Vivo"


def get_random_user_agent() -> str:
    """Retorna un User-Agent aleatorio."""
    return random.choice(USER_AGENTS)


# ============================================================================
# EXTRACTORES DE STREAMS - ULTRA AGRESIVOS
# ============================================================================

def extract_zeno_stream(url: str) -> Optional[str]:
    """Extrae stream de Zeno.FM con m√∫ltiples m√©todos."""
    try:
        parsed = urlparse(url)
        
        # M√©todo 1: Ya es stream directo
        if "stream.zeno.fm" in parsed.netloc:
            for attempt in range(3):
                try:
                    resp = requests.head(url, timeout=8, allow_redirects=True)
                    if resp.status_code == 200:
                        logger.info(f"[OK] Stream Zeno valido: {url}")
                        return url
                except:
                    time.sleep(1)
        
        # M√©todo 2: Extraer ID de la URL
        if "zeno.fm" in parsed.netloc:
            # Buscar ID en el path o query
            stream_id = None
            
            # En el path: /radio/station-name/ -> buscar en HTML
            if "/radio/" in parsed.path:
                try:
                    headers = {'User-Agent': get_random_user_agent()}
                    resp = requests.get(url, headers=headers, timeout=15)
                    
                    # Buscar el stream ID en diferentes formatos
                    patterns = [
                        r'stream\.zeno\.fm/([a-z0-9]+)',
                        r'"streamUrl"\s*:\s*"[^"]*?/([a-z0-9]+)"',
                        r'data-stream-id="([a-z0-9]+)"',
                        r'streamid["\s:=]+([a-z0-9]+)'
                    ]
                    
                    for pattern in patterns:
                        match = re.search(pattern, resp.text, re.IGNORECASE)
                        if match:
                            stream_id = match.group(1)
                            break
                    
                    if stream_id:
                        stream_url = f"https://stream.zeno.fm/{stream_id}"
                        # Validar que funcione
                        try:
                            test_resp = requests.head(stream_url, timeout=8)
                            if test_resp.status_code == 200:
                                logger.info(f"[OK] Stream Zeno extraido: {stream_url}")
                                return stream_url
                        except:
                            pass
                    
                except Exception as e:
                    logger.debug(f"Error extrayendo Zeno HTML: {e}")
            
            # M√©todo 3: Si la URL ya tiene el ID directamente
            path_parts = parsed.path.strip('/').split('/')
            for part in path_parts:
                if len(part) > 6 and part.isalnum():
                    test_url = f"https://stream.zeno.fm/{part}"
                    try:
                        resp = requests.head(test_url, timeout=8)
                        if resp.status_code == 200:
                            logger.info(f"[OK] Stream Zeno por path: {test_url}")
                            return test_url
                    except:
                        continue
        
        return None
        
    except Exception as e:
        logger.debug(f"Error procesando Zeno: {e}")
        return None


def extract_radionet_stream(url: str) -> Optional[str]:
    """Extrae stream de Radio.net con m√∫ltiples intentos."""
    try:
        parsed = urlparse(url)
        
        if "radio.net" not in parsed.netloc:
            return None
        
        # Extraer nombre de la estaci√≥n
        station_name = None
        
        # De query params: ?station=nombre
        if "station=" in url:
            match = re.search(r'station=([^&]+)', url)
            if match:
                station_name = match.group(1)
        
        # Del path: /radio/nombre/
        if not station_name:
            match = re.search(r'/radio/([^/]+)', parsed.path)
            if match:
                station_name = match.group(1)
        
        if station_name:
            # Intentar m√∫ltiples formatos de URL de stream
            possible_urls = [
                f"https://{station_name}.stream.radio.net/stream",
                f"https://stream.radio.net/{station_name}",
                f"https://edge.radio.net/{station_name}/stream",
                f"http://stream.radio.net/{station_name}.m3u",
                f"https://{station_name}.radio.net/live",
            ]
            
            for test_url in possible_urls:
                for attempt in range(2):
                    try:
                        resp = requests.head(test_url, timeout=10, allow_redirects=True)
                        if resp.status_code == 200:
                            logger.info(f"[OK] Stream Radio.net: {test_url}")
                            return test_url
                    except:
                        time.sleep(0.5)
        
        # √öltimo recurso: buscar en el HTML
        try:
            headers = {'User-Agent': get_random_user_agent()}
            resp = requests.get(url, headers=headers, timeout=15)
            
            # Buscar URLs de stream en el HTML
            stream_patterns = [
                r'https://[^"\s]+\.stream\.radio\.net[^"\s]*',
                r'"streamUrl"\s*:\s*"([^"]+)"',
            ]
            
            for pattern in stream_patterns:
                matches = re.findall(pattern, resp.text, re.IGNORECASE)
                for match in matches:
                    potential_url = match if isinstance(match, str) else match[0]
                    try:
                        test_resp = requests.head(potential_url, timeout=8)
                        if test_resp.status_code == 200:
                            logger.info(f"[OK] Stream Radio.net HTML: {potential_url}")
                            return potential_url
                    except:
                        continue
        except:
            pass
        
        return None
        
    except Exception as e:
        logger.debug(f"Error extrayendo Radio.net: {e}")
        return None


def extract_generic_stream(page_url: str) -> Optional[str]:
    """Extractor gen√©rico AGRESIVO."""
    try:
        headers = {'User-Agent': get_random_user_agent()}
        
        for attempt in range(3):
            try:
                resp = requests.get(page_url, headers=headers, timeout=15)
                content = resp.text
                break
            except:
                if attempt < 2:
                    time.sleep(2)
                    continue
                return None
        
        # Buscar TODOS los patrones posibles
        stream_patterns = [
            # Extensiones de audio
            r'https?://[^\s"\'<>]+\.(?:mp3|aac|ogg|opus|pls|m3u|m3u8|xspf)',
            # Puertos de streaming
            r'https?://[^\s"\'<>]+:[0-9]{4,5}/[^\s"\'<>]*',
            # Atributos comunes
            r'"streamUrl"\s*:\s*"([^"]+)"',
            r'"stream"\s*:\s*"([^"]+)"',
            r'"audioUrl"\s*:\s*"([^"]+)"',
            r'data-stream="([^"]+)"',
            r'src="(https?://[^"]+\.(?:mp3|m3u8|aac))"',
            r'href="(https?://[^"]+\.(?:pls|m3u))"',
            # Icecast/Shoutcast
            r'https?://[^\s"\'<>]*icecast[^\s"\'<>]*',
            r'https?://[^\s"\'<>]*shoutcast[^\s"\'<>]*',
        ]
        
        found_urls = set()
        for pattern in stream_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                url = match if isinstance(match, str) else match[0]
                found_urls.add(url)
        
        # Validar cada URL encontrada
        for potential_url in found_urls:
            try:
                test_resp = requests.head(potential_url, timeout=8, allow_redirects=True)
                if test_resp.status_code == 200:
                    logger.info(f"[OK] Stream generico: {potential_url}")
                    return potential_url
            except:
                continue
        
        return None
        
    except Exception as e:
        logger.debug(f"Error extracci√≥n gen√©rica: {e}")
        return None


def get_real_stream_url(url: str) -> str:
    """
    Obtiene URL real del stream - VERSI√ìN R√ÅPIDA.
    M√ÅXIMO 5 SEGUNDOS por emisora, no m√°s.
    """
    if not url:
        return url
    
    # Verificar cach√©
    if url in STREAM_URL_CACHE:
        return STREAM_URL_CACHE[url]
    
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    
    # Si parece stream directo, validar y retornar R√ÅPIDO
    if any(ext in url.lower() for ext in ['.mp3', '.aac', '.ogg', '.m3u', '.pls']):
        try:
            resp = requests.head(url, timeout=3, allow_redirects=True)
            if resp.status_code == 200:
                STREAM_URL_CACHE[url] = url
                return url
        except:
            pass
    
    # Si tiene puerto de streaming t√≠pico
    if re.search(r':[0-9]{4,5}/', url):
        STREAM_URL_CACHE[url] = url
        return url
    
    # ESTRATEGIA R√ÅPIDA: Solo 1 intento por plataforma (no 3)
    real_url = None
    
    if "radio.net" in domain:
        logger.info("[WRENCH] Detectado Radio.net")
        # Extraer nombre directo
        match = re.search(r'/radio/([^/]+)', parsed.path)
        if match:
            station_name = match.group(1)
            # Intentar formato m√°s directo primero
            test_urls = [
                f"https://{station_name}.stream.radio.net/stream",
                f"https://stream.radio.net/{station_name}",
            ]
            for test_url in test_urls:
                try:
                    resp = requests.head(test_url, timeout=2, allow_redirects=True)
                    if resp.status_code == 200:
                        real_url = test_url
                        break
                except:
                    continue
    
    elif "zeno.fm" in domain:
        logger.info("[WRENCH] Detectado Zeno.FM")
        # Zeno es m√°s simple - su URL suele ser ya v√°lida
        real_url = url
    
    # Cachear resultado - siempre usar algo
    final_url = real_url if real_url else url
    STREAM_URL_CACHE[url] = final_url
    
    return final_url


# ============================================================================
# DETECCI√ìN ICY METADATA - ULTRA PERSISTENTE
# ============================================================================

def get_icy_metadata(stream_url: str, timeout: int = 8) -> Optional[str]:
    """Lee metadata ICY - VERSI√ìN R√ÅPIDA."""
    headers_variants = [
        {"Icy-MetaData": "1", "User-Agent": "RadioMonitor/3.0"},
        {"Icy-Metadata": "1", "User-Agent": "VLC/3.0.0"},
        {"User-Agent": "Mozilla/5.0"},
    ]
    
    for attempt in range(MAX_RETRIES_ICY):
        # Reducir timeout en reintentos
        current_timeout = timeout if attempt == 0 else max(3, timeout - attempt)
        headers = headers_variants[attempt % len(headers_variants)]
        
        try:
            resp = requests.get(
                stream_url,
                headers=headers,
                stream=True,
                timeout=current_timeout
            )
            
            # Intentar obtener metadata de HTTP headers PRIMERO (m√°s r√°pido)
            for header_key in ['icy-title', 'Title', 'X-StreamTitle']:
                for k in resp.headers:
                    if k.lower() == header_key.lower():
                        title = resp.headers[k]
                        if title and is_valid_metadata(title):
                            logger.info(f"   [OK] ICY header: {title[:60]}")
                            resp.close()
                            return normalize_string(title)
                        break
            
            # Buscar metaint para ICY metadata (streaming)
            metaint_key = None
            for key in resp.headers:
                if 'metaint' in key.lower():
                    metaint_key = key
                    break
            
            if not metaint_key:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)  # Solo 0.5s entre intentos
                continue
            
            try:
                metaint = int(resp.headers[metaint_key])
            except:
                resp.close()
                continue
            
            raw = resp.raw
            
            # Leer bloque de datos
            data_block = raw.read(metaint)
            if not data_block:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            # Leer longitud de metadata
            meta_len_byte = raw.read(1)
            if not meta_len_byte:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            meta_len = meta_len_byte[0] * 16
            if meta_len == 0:
                resp.close()
                if attempt < MAX_RETRIES_ICY - 1:
                    time.sleep(0.5)
                continue
            
            # Leer metadata
            meta = raw.read(meta_len)
            resp.close()
            
            # Extraer t√≠tulo - simple y r√°pido
            title = None
            for prefix in [b"StreamTitle='", b"Title='"]:
                if prefix in meta:
                    try:
                        title_part = meta.split(prefix, 1)[1]
                        for end in [b"';", b"'"]:
                            if end in title_part:
                                title = title_part.split(end)[0].decode("utf-8", errors="ignore").strip()
                                break
                        if not title:
                            title = title_part[:200].decode("utf-8", errors="ignore").strip()
                        if title:
                            break
                    except:
                        pass
            
            if title:
                title_clean = clean_stream_title(title)
                if is_valid_metadata(title_clean):
                    logger.info(f"   [OK] ICY metadata: {title_clean[:60]}")
                    return normalize_string(title_clean)
            
            if attempt < MAX_RETRIES_ICY - 1:
                time.sleep(0.5)
            
        except Exception as e:
            if attempt < MAX_RETRIES_ICY - 1:
                time.sleep(0.5)
    
    return None


# ============================================================================
# RECONOCIMIENTO POR AUDIO - VERSI√ìN R√ÅPIDA
# ============================================================================

def capture_and_recognize_acrcloud(stream_url: str, access_key: str, secret_key: str) -> Optional[Dict[str, Any]]:
    """Captura y reconoce con ACRCloud (Gratuito - 1000 req/mes)."""
    
    if not access_key or not secret_key:
        return None
    
    if not FFMPEG_AVAILABLE:
        logger.debug("   Skipping ACRCloud: ffmpeg not available")
        return None
    
    for attempt in range(MAX_RETRIES_AUDD):
        sample_path = os.path.join(TEMP_DIR, f"sample_{int(time.time())}_{os.getpid()}_{attempt}.wav")
        
        duration = SAMPLE_DURATION
        
        cmd = [
            "ffmpeg", "-y",
            "-hide_banner", "-loglevel", "quiet",
            "-i", stream_url,
            "-t", str(duration),
            "-ac", "1",
            "-ar", "44100",
            "-f", "wav",
            sample_path
        ]
        
        try:
            logger.debug(f"   Capturando audio {duration}s...")
            
            subprocess.run(
                cmd,
                check=True,
                timeout=duration + 5,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            if not os.path.exists(sample_path) or os.path.getsize(sample_path) < 500:
                logger.debug(f"   Audio muy peque√±o o falla")
                try:
                    os.remove(sample_path)
                except:
                    pass
                if attempt < MAX_RETRIES_AUDD - 1:
                    time.sleep(0.5)
                    continue
                return None
            
            # Preparar archivo de audio
            with open(sample_path, "rb") as f:
                audio_data = f.read()
            
            # Generar firma ACRCloud
            timestamp = str(int(time.time()))
            string_to_sign = f"POST\n/v1/identify\n{access_key}\naudio/wav\n{timestamp}"
            signature = base64.b64encode(
                hmac.new(
                    secret_key.encode(),
                    string_to_sign.encode(),
                    hashlib.sha1
                ).digest()
            ).decode()
            
            # Enviar a ACRCloud
            logger.debug(f"   Enviando a ACRCloud...")
            headers = {
                "Content-Type": "audio/wav",
                "Authorization": f"ACRCloud {access_key}:{signature}",
                "x-ac-data-type": "audio",
                "x-ac-media-type": "recording",
                "x-ac-timestamp": timestamp
            }
            
            resp = requests.post(
                "https://identify-us-west-2.acrcloud.com/v1/identify",
                headers=headers,
                data=audio_data,
                timeout=30
            )
            
            try:
                os.remove(sample_path)
            except:
                pass
            
            # Guardar respuesta para an√°lisis
            try:
                fname = os.path.join(TEMP_DIR, f"acrcloud_resp_{int(time.time())}_{os.getpid()}.json")
                with open(fname, "w", encoding="utf-8") as _f:
                    _f.write(resp.text)
                logger.debug(f"   ACRCloud: respuesta guardada en {fname}")
            except Exception:
                pass
            
            if resp.status_code == 200:
                try:
                    j = resp.json()
                except Exception:
                    j = None
                
                if j and j.get("status") == 0 and j.get("metadata"):
                    metadata = j["metadata"]
                    
                    # ACRCloud puede tener m√∫ltiples resultados (music, humming, etc)
                    music_results = metadata.get("music", [])
                    
                    if music_results:
                        result = music_results[0]
                        artist = result.get("artists", [{}])[0].get("name", "").strip()
                        title = result.get("title", "").strip()
                        
                        if artist and title and is_valid_metadata(artist) and is_valid_metadata(title):
                            # Extraer g√©nero
                            genre = "Desconocido"
                            
                            # Intentar obtener g√©nero de los datos
                            if "genres" in result and result["genres"]:
                                genre = result["genres"][0].get("name", "Desconocido")
                            
                            # Si no hay g√©nero, consultar MusicBrainz
                            if genre == "Desconocido":
                                mb_genre = get_genre_musicbrainz(artist, title)
                                if mb_genre:
                                    genre = mb_genre
                            
                            logger.info(f"   [OK] ACRCloud reconocio exitosamente: {artist} - {title}")
                            return {
                                "artist": artist,
                                "title": title,
                                "genre": genre
                            }
            
            logger.debug(f"   ACRCloud: no reconoci√≥ (attempt {attempt + 1}/{MAX_RETRIES_AUDD})")
            if attempt < MAX_RETRIES_AUDD - 1:
                time.sleep(RETRY_DELAY * 2)
        
        except subprocess.TimeoutExpired:
            logger.debug(f"   Timeout capturando audio")
        except Exception as e:
            logger.debug(f"   Error ACRCloud: {str(e)[:50]}")
        finally:
            try:
                if os.path.exists(sample_path):
                    os.remove(sample_path)
            except:
                pass
        
        if attempt < MAX_RETRIES_AUDD - 1:
            time.sleep(RETRY_DELAY)
    
    logger.debug(f"   ACRCloud: todos los intentos agotados")
    return None


def capture_and_recognize_audd(stream_url: str, audd_token: str) -> Optional[Dict[str, Any]]:
    """Captura y reconoce con AudD (fallback si ACRCloud falla)."""
    global AUDD_ENABLED, AUDD_FAILURES, AUDD_LAST_FAILURE

    if not audd_token:
        return None

    # Si ffmpeg no est√° disponible no intentamos capturar
    if not FFMPEG_AVAILABLE:
        logger.debug("   Skipping AudD: ffmpeg not available")
        return None

    # Si circuit-breaker est√° activado por fallos previos, comprobar cooldown
    if not AUDD_ENABLED:
        if AUDD_LAST_FAILURE and (time.time() - AUDD_LAST_FAILURE) < AUDD_COOLDOWN:
            logger.debug("   AudD disabled due to recent failures; skipping")
            return None
        else:
            # cooldown expir√≥, reactivar
            AUDD_ENABLED = True
            AUDD_FAILURES = 0
            AUDD_LAST_FAILURE = None
    
    for attempt in range(MAX_RETRIES_AUDD):
        sample_path = os.path.join(TEMP_DIR, f"sample_{int(time.time())}_{os.getpid()}_{attempt}.wav")
        
        # Duraci√≥n consistente
        duration = SAMPLE_DURATION
        
        cmd = [
            "ffmpeg", "-y",
            "-hide_banner", "-loglevel", "quiet",
            "-i", stream_url,
            "-t", str(duration),
            "-ac", "1",
            "-ar", "44100",
            "-f", "wav",
            sample_path
        ]
        
        try:
            logger.debug(f"   Capturando audio {duration}s...")
            
            # Timeout m√°s corto: duration + 5s
            subprocess.run(
                cmd,
                check=True,
                timeout=duration + 5,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            if not os.path.exists(sample_path) or os.path.getsize(sample_path) < 500:
                logger.debug(f"   Audio muy peque√±o o falla")
                try:
                    os.remove(sample_path)
                except:
                    pass
                if attempt < MAX_RETRIES_AUDD - 1:
                    time.sleep(0.5)
                    continue
                return None
            
            # Enviar a AudD
            logger.debug(f"   Enviando a AudD...")
            with open(sample_path, "rb") as f:
                files = {"file": ("sample.wav", f, "audio/wav")}
                data = {"api_token": audd_token, "return": "spotify"}
                
                # Aumentar timeout por si la resoluci√≥n toma algo m√°s
                resp = requests.post(
                    "https://api.audd.io/",
                    files=files,
                    data=data,
                    timeout=30
                )
            
            try:
                os.remove(sample_path)
            except:
                pass
            
            # Log y diagn√≥stico: guardar respuesta completa para an√°lisis si falla
            try:
                status_code = resp.status_code
                text = resp.text
            except Exception:
                status_code = None
                text = None

            logger.debug(f"   AudD HTTP status: {status_code}")

            # Guardar respuesta cruda para an√°lisis en tmp
            try:
                if text:
                    fname = os.path.join(TEMP_DIR, f"audd_resp_{int(time.time())}_{os.getpid()}.json")
                    with open(fname, "w", encoding="utf-8") as _f:
                        _f.write(text)
                    logger.debug(f"   AudD: respuesta guardada en {fname}")
            except Exception:
                pass

            if resp.status_code == 200:
                try:
                    j = resp.json()
                except Exception:
                    j = None
                if j and j.get("status") == "success" and j.get("result"):
                    result = j["result"]
                    # √âxito -> reset failures
                    AUDD_FAILURES = 0
                    AUDD_LAST_FAILURE = None
                    
                    artist = result.get("artist")
                    title = result.get("title")
                    
                    if artist and title and is_valid_metadata(artist) and is_valid_metadata(title):
                        # Extraer g√©nero
                        genre = "Desconocido"
                        
                        if "spotify" in result and result["spotify"]:
                            spotify_data = result["spotify"]
                            if "album" in spotify_data and "genres" in spotify_data["album"]:
                                genres = spotify_data["album"]["genres"]
                                if genres:
                                    genre = genres[0]
                        
                        if genre == "Desconocido" and "apple_music" in result and result["apple_music"]:
                            apple_data = result["apple_music"]
                            if "genreNames" in apple_data and apple_data["genreNames"]:
                                genre = apple_data["genreNames"][0]
                        
                        logger.info(f"   [OK] AudD reconocio exitosamente")
                        return {
                            "artist": artist,
                            "title": title,
                            "genre": genre
                        }
                else:
                    # fallo l√≥gico de AudD (respuesta vac√≠a o status!=success)
                    AUDD_FAILURES += 1
                    AUDD_LAST_FAILURE = time.time()
                    logger.debug(f"   AudD logical failure count: {AUDD_FAILURES}")
                    if AUDD_FAILURES >= AUDD_FAILURE_THRESHOLD:
                        AUDD_ENABLED = False
                        logger.warning("AudD deshabilitado temporalmente por fallos repetidos (circuit-breaker)")
            
            if attempt < MAX_RETRIES_AUDD - 1:
                logger.debug(f"   AudD: no reconoci√≥, reintentando...")
                time.sleep(RETRY_DELAY * 2)
            
        except subprocess.TimeoutExpired:
            logger.debug(f"   Timeout capturando audio")
        except Exception as e:
            logger.debug(f"   Error AudD: {str(e)[:50]}")
        finally:
            try:
                if os.path.exists(sample_path):
                    os.remove(sample_path)
            except:
                pass
        
        if attempt < MAX_RETRIES_AUDD - 1:
            time.sleep(RETRY_DELAY)
    
    logger.debug(f"   AudD: todos los intentos agotados")
    # marcar fallo general
    try:
        AUDD_FAILURES += 1
        AUDD_LAST_FAILURE = time.time()
        if AUDD_FAILURES >= AUDD_FAILURE_THRESHOLD:
            AUDD_ENABLED = False
            logger.warning("AudD deshabilitado temporalmente por fallos repetidos (circuit-breaker)")
    except Exception:
        pass
    return None


# ============================================================================
# G√âNERO MUSICBRAINZ
# ============================================================================

def get_genre_from_cache(artist: str) -> Optional[str]:
    """Obtiene g√©nero del cach√©."""
    key = artist.lower().strip()
    return GENRE_CACHE.get(key)


def save_genre_to_cache(artist: str, genre: str):
    """Guarda g√©nero en cach√©."""
    key = artist.lower().strip()
    GENRE_CACHE[key] = genre


def get_genre_musicbrainz(artist: str, title: str) -> Optional[str]:
    """Consulta g√©nero en MusicBrainz."""
    try:
        url = "https://musicbrainz.org/ws/2/recording/"
        params = {
            "query": f'artist:"{artist}" AND recording:"{title}"',
            "fmt": "json",
            "limit": 1
        }
        headers = {"User-Agent": "RadioMonitor/3.0 (professional@radiomonitor.com)"}
        
        resp = requests.get(url, params=params, headers=headers, timeout=12)
        
        if resp.status_code == 200:
            data = resp.json()
            if data.get("recordings"):
                recording = data["recordings"][0]
                if "tags" in recording and recording["tags"]:
                    tags = sorted(recording["tags"], key=lambda x: x.get("count", 0), reverse=True)
                    if tags:
                        genre = tags[0].get("name")
                        if genre:
                            return genre.title()
        
        return None
        
    except Exception as e:
        logger.debug(f"Error MusicBrainz: {e}")
        return None


# ============================================================================
# DUPLICADOS
# ============================================================================

def is_recent_duplicate(db, Cancion, emisora_id: int, artista: str, titulo: str, seconds: int = 300) -> bool:
    """Verifica duplicado reciente."""
    try:
        last = (
            Cancion.query
            .filter_by(emisora_id=emisora_id)
            .order_by(Cancion.fecha_reproduccion.desc())
            .first()
        )
        
        if not last:
            return False
        
        def clean(s):
            return normalize_string(s).lower()
        
        if clean(last.artista) == clean(artista) and clean(last.titulo) == clean(titulo):
            delta = (datetime.now() - last.fecha_reproduccion).total_seconds()
            return delta <= seconds
        
        return False
        
    except Exception as e:
        logger.debug(f"Error verificando duplicado: {e}")
        return False


# ============================================================================
# FUNCI√ìN PRINCIPAL - NIVEL PERIOD√çSTICO PROFESIONAL
# ============================================================================

def actualizar_emisoras(fallback_to_audd=True, dedupe_seconds=DEDUPE_SECONDS, audd_token: str = None):
    """
    [OK] VERSI√ìN PERIOD√çSTICA PROFESIONAL
    NO SE RINDE. GARANT√çA 100% DE REGISTRO.
    Usa ACRCloud (gratuito, 1000 req/mes) como primario, AudD como fallback.
    """
    try:
        from flask import current_app
        from utils.db import db
        from models.emisoras import Emisora, Cancion
        
        app = current_app._get_current_object()
        
        logger.info("=" * 70)
        logger.info("[OK] SISTEMA PERIOD√çSTICO PROFESIONAL - INICIANDO")
        logger.info("=" * 70)
        
        # Cargar credenciales
        acrcloud_key = app.config.get("ACRCLOUD_ACCESS_KEY", "")
        acrcloud_secret = app.config.get("ACRCLOUD_SECRET_KEY", "")
        audd_token = audd_token if audd_token is not None else app.config.get("AUDD_API_TOKEN", "")
        
        emisoras = Emisora.query.all()
        
        if not emisoras:
            logger.warning("[WARN]  Sin emisoras en BD")
            return
        
        logger.info(f"[RADIO] {len(emisoras)} emisoras a procesar\n")
        
        stats = {
            "processed": 0,
            "registered": 0,
            "icy_success": 0,
            "acrcloud_success": 0,
            "audd_success": 0,
            "mb_genre": 0,
            "duplicates": 0,
            "errors": 0
        }
        
        for idx, e in enumerate(emisoras, 1):
            try:
                logger.info(f"{'=' * 70}")
                logger.info(f"[SIGNAL] [{idx}/{len(emisoras)}] {e.nombre} (ID: {e.id})")
                logger.info(f"{'-' * 70}")
                
                url = getattr(e, "url_stream", None) or getattr(e, "url", None)
                
                if not url:
                    logger.error(f"[ERROR] Sin URL - OMITIENDO")
                    stats["errors"] += 1
                    continue
                
                # OBTENER STREAM REAL
                logger.info(f"[CHECK] Obteniendo stream real...")
                stream_url = get_real_stream_url(url)
                logger.info(f"   URL final: {stream_url[:80]}...")
                
                detected_info = None
                
                # PASO 1: ICY METADATA (5 INTENTOS)
                logger.info(f"[MUSIC] Intentando ICY metadata ({MAX_RETRIES_ICY} intentos)...")
                icy_title = get_icy_metadata(stream_url, timeout=ICY_TIMEOUT)
                
                if icy_title:
                    logger.info(f"   [RAW] Obtenido: {icy_title[:100]}")
                    if is_valid_metadata(icy_title):
                        artista, titulo = parse_title_artist(icy_title)
                        
                        if is_valid_metadata(artista) and is_valid_metadata(titulo):
                            detected_info = {
                                "artist": artista,
                                "title": titulo,
                                "genre": None,
                                "fuente": "icy"
                            }
                            stats["icy_success"] += 1
                            logger.info(f"[SUCCESS] ICY EXITOSO: {artista} - {titulo}")
                        else:
                            logger.info(f"   [REJECT] Artista o titulo inv√°lido: '{artista}' - '{titulo}'")
                    else:
                        logger.info(f"   [REJECT] ICY metadata rechazada por validaci√≥n (gen√©rica/falsa)")
                else:
                    logger.info(f"   [FAIL] No se obtuvo ICY metadata (timeout o sin metadata)")
                
                # PASO 2: RECONOCIMIENTO POR AUDIO (ACRCloud ‚Üí AudD)
                if not detected_info:
                    # Intentar ACRCloud primero (gratuito, 1000 req/mes)
                    if acrcloud_key and acrcloud_secret:
                        logger.info(f"[AUDIO] Intentando ACRCloud (gratuito, 1000 req/mes)...")
                        acrcloud_result = capture_and_recognize_acrcloud(stream_url, acrcloud_key, acrcloud_secret)
                        
                        if acrcloud_result:
                            detected_info = acrcloud_result
                            detected_info["fuente"] = "acrcloud"
                            stats["acrcloud_success"] += 1
                            logger.info(f"[SUCCESS] ACRCLOUD EXITOSO: {acrcloud_result['artist']} - {acrcloud_result['title']}")
                            if acrcloud_result.get("genre") and acrcloud_result["genre"] != "Desconocido":
                                logger.info(f"   [GENRE] G√©nero detectado: {acrcloud_result['genre']}")
                        else:
                            logger.info(f"   [FAIL] ACRCloud no pudo detectar canci√≥n")
                    else:
                        logger.info(f"[WARN]  ACRCloud no configurado (credenciales faltantes)")
                    
                    # Fallback a AudD si ACRCloud fall√≥
                    if not detected_info and audd_token:
                        logger.info(f"[AUDIO] Fallback: Intentando AudD...")
                        audd_result = capture_and_recognize_audd(stream_url, audd_token)
                        
                        if audd_result:
                            detected_info = audd_result
                            detected_info["fuente"] = "audd"  # Marcar fuente
                            stats["audd_success"] += 1
                            logger.info(f"[SUCCESS] AUDD EXITOSO: {audd_result['artist']} - {audd_result['title']}")
                            if audd_result.get("genre") and audd_result["genre"] != "Desconocido":
                                logger.info(f"   [GENRE] G√©nero detectado: {audd_result['genre']}")
                        else:
                            logger.info(f"   [FAIL] AudD no pudo detectar canci√≥n")
                
                # PASO 3: OBTENER G√âNERO SI FALTA
                if detected_info:
                    artista = detected_info["artist"]
                    titulo = detected_info["title"]
                    genero = detected_info.get("genre", "Desconocido")
                    
                    if not genero or genero == "Desconocido":
                        # Cach√©
                        cached_genre = get_genre_from_cache(artista)
                        if cached_genre:
                            detected_info["genre"] = cached_genre
                            genero = cached_genre
                            logger.info(f"   [GENRE] G√©nero (cach√©): {cached_genre}")
                        else:
                            # MusicBrainz
                            logger.info(f"[CHECK] Consultando g√©nero en MusicBrainz...")
                            mb_genre = get_genre_musicbrainz(artista, titulo)
                            if mb_genre:
                                detected_info["genre"] = mb_genre
                                genero = mb_genre
                                save_genre_to_cache(artista, mb_genre)
                                stats["mb_genre"] += 1
                                logger.info(f"   [SUCCESS] G√©nero: {mb_genre}")
                            else:
                                detected_info["genre"] = "Desconocido"
                                genero = "Desconocido"
                
                # PASO 4: SIN FALLBACK PREDICTIVO - SOLO DATOS AUT√âNTICOS
                # Si no hay ICY metadata ni AudD/ACRCloud exitoso ‚Üí NO registrar nada
                if not detected_info:
                    logger.warning(f"[SKIP]  NO SE PUDO VERIFICAR CANCI√ìN - Sin ICY metadata ni reconocimiento ACRCloud/AudD exitoso")
                    logger.warning(f"         (Se omite registro para garantizar autenticidad de datos)")
                    stats["processed"] += 1
                    e.ultima_actualizacion = datetime.now()
                    db.session.commit()
                    continue

                
                if is_recent_duplicate(db, Cancion, e.id, artista, titulo, dedupe_seconds):
                    logger.info(f"[SKIP]  DUPLICADO RECIENTE - Omitiendo")
                    stats["duplicates"] += 1
                    e.ultima_actualizacion = datetime.now()
                    db.session.commit()
                    stats["processed"] += 1
                    continue
                
                # PASO 6: GUARDAR EN BASE DE DATOS
                logger.info(f"[SAVE] GUARDANDO EN BD...")
                logger.info(f"   Artista: {artista}")
                logger.info(f"   T√≠tulo:  {titulo}")
                logger.info(f"   G√©nero:  {genero}")
                if detected_info.get("fuente"):
                    logger.info(f"   Fuente:  {detected_info.get('fuente', 'icy').upper()}")
                
                nueva = Cancion(
                    titulo=titulo,
                    artista=artista,
                    genero=genero,
                    emisora_id=e.id,
                    fecha_reproduccion=datetime.now(),
                    fuente=detected_info.get("fuente", "icy"),
                    razon_prediccion=detected_info.get("razon_prediccion", None),
                    confianza_prediccion=detected_info.get("confianza_prediccion", None)
                )
                
                db.session.add(nueva)
                e.ultima_cancion = f"{artista} - {titulo}"
                e.ultima_actualizacion = datetime.now()
                db.session.commit()
                
                stats["registered"] += 1
                logger.info(f"[SUCCESS] [SUCCESS] [SUCCESS] REGISTRADO EXITOSAMENTE [SUCCESS] [SUCCESS] [SUCCESS]")
                
                stats["processed"] += 1
                
            except Exception as exc:
                logger.error(f"[ERROR] ERROR PROCESANDO {e.nombre}: {exc}")
                import traceback
                traceback.print_exc()
                stats["errors"] += 1
                try:
                    db.session.rollback()
                except:
                    pass
        
        # ESTAD√çSTICAS FINALES
        logger.info(f"\n{'=' * 70}")
        logger.info(f"[OK] CICLO COMPLETADO - REPORTE FINAL (SOLO DATOS AUT√âNTICOS)")
        logger.info(f"{'=' * 70}")
        logger.info(f"üìä Total procesadas:    {stats['processed']}/{len(emisoras)}")
        logger.info(f"[SUCCESS] ‚úì Registradas (AUT√âNTICAS): {stats['registered']}")
        logger.info(f"  ‚îú‚îÄ [MUSIC] ICY metadata:   {stats['icy_success']}")
        logger.info(f"  ‚îú‚îÄ [AUDIO] ACRCloud:       {stats['acrcloud_success']}")
        logger.info(f"  ‚îî‚îÄ [AUDIO] AudD:           {stats['audd_success']}")
        logger.info(f"[GENRE] MusicBrainz:          {stats['mb_genre']}")
        logger.info(f"[SKIP]  ‚úó Omitidas (sin verificaci√≥n): {stats['duplicates']}")
        logger.info(f"[ERROR] Errores de conexi√≥n:  {stats['errors']}")
        logger.info(f"{'-' * 70}")
        if stats['processed'] > 0:
            success_rate = (stats['registered'] / stats['processed']) * 100
            logger.info(f"[OK] TASA DE AUTENTICIDAD: {success_rate:.1f}%")
            logger.info(f"[NOTE] Solo se registran datos verificados (ICY, ACRCloud o AudD).")
            logger.info(f"       ACRCloud: Gratuito, 1000 req/mes | AudD: Fallback si disponible")
        logger.info(f"{'=' * 70}\n")
        
    except Exception as exc:
        logger.error(f"[ERROR] ERROR CR√çTICO EN SISTEMA: {exc}")
        import traceback
        traceback.print_exc()